# -*- coding: utf-8 -*-
"""NNDL_miniproj3_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HqvJ_OQdc2b5_8INsmuZZqWRdurY2ujq

# NNDL miniproj3 Question1: VAE
sajjad pakdaman    [810195517]

fatemeh haghighi   [810195385]

## setup
import necessary libs
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape, MaxPool2D, BatchNormalization

"""## load MNIST"""

(f_tra, l_tra), (f_tes, l_tes) = keras.datasets.mnist.load_data()

img_width, img_height = f_tra.shape[1], f_tra.shape[2]
batch_size = 128
no_epochs = 50
validation_split = 0.2
verbosity = 1
latent_dim = 2
num_channels = 1

plt.imshow(f_tra[0])
plt.title(l_tra[0])

"""## Data preprocessing"""

# Parse numbers as floats
f_tra = (f_tra.astype('float32') / 255).reshape(f_tra.shape[0], img_height, img_width, num_channels)
f_tes = (f_tes.astype('float32') / 255).reshape(f_tes.shape[0], img_height, img_width, num_channels)

"""## sampling layer using reparametrization trick"""

class Sampling(layers.Layer):
    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon

"""## Encoder"""

i      = Input(shape=(img_height, img_width, num_channels), name='encoder_input') #(28, 28, 1)

x      = Conv2D(filters=4, kernel_size=5, strides=1, activation='relu', name='layer1')(i) #(24, 24, 4)
# x      = BatchNormalization()(x)

x      = Conv2D(filters=8, kernel_size=5, strides=1, activation='relu')(x) #(20, 20, 8)
# x      = BatchNormalization()(x)

x      = Conv2D(filters=16, kernel_size=5, strides=1, activation='relu')(x) #(16, 16, 16)
# x      = BatchNormalization()(x)

x      = Flatten()(x) #(16*16*16, )
x      = Dense(16*16)(x) #(16*16, )
# x      = BatchNormalization()(x)

mu     = Dense(latent_dim, name='z_mu')(x) #(2, )
sigma  = Dense(latent_dim, name='z_log_sigma')(x) #(2, )
z      = Sampling()([mu, sigma])

encoder = keras.Model(i, [mu, sigma, z], name="encoder")
encoder.summary()

"""## Decoder"""

latent_i = keras.Input(shape=(latent_dim,))
x        = layers.Dense(16*16, activation="relu")(latent_i)
# x        = BatchNormalization()(x)

x        = layers.Dense(16*16*16, activation="relu")(x)
x        = layers.Reshape((16, 16, 16))(x)
# x        = BatchNormalization()(x)

x        = layers.Conv2DTranspose(8, 5, activation="relu", strides=1)(x)
# x        = BatchNormalization()(x)
x        = layers.Conv2DTranspose(4, 5, activation="relu", strides=1)(x)
# x        = BatchNormalization()(x)
o        = layers.Conv2DTranspose(1, 5, activation="sigmoid", strides=1)(x)

decoder = keras.Model(latent_i, o, name="decoder")
decoder.summary()

"""## VAE Model"""

class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder

    def train_step(self, data):
        if isinstance(data, tuple):
            data = data[0]
        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = encoder(data)
            reconstruction = decoder(z)
            reconstruction_loss = tf.reduce_mean(
                keras.losses.binary_crossentropy(data, reconstruction)
            )
            reconstruction_loss *= 28 * 28
            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
            kl_loss = tf.reduce_mean(kl_loss)
            kl_loss *= -0.5
            total_loss = reconstruction_loss + kl_loss
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        return {
            "loss": total_loss,
            "reconstruction_loss": reconstruction_loss,
            "kl_loss": kl_loss,
        }

"""## init the vae"""

vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.002))

"""## train model"""

F = np.concatenate([f_tra, f_tes], axis=0)
F.shape

"""## visualization"""

def viz_latent_space(epoch, verbos=False):
    cmap = plt.cm.get_cmap('jet', 10)
    mu, _, _ = encoder.predict(f_tra)
    plt.figure(figsize=(8, 8))
    for l in np.unique(l_tra):
        mask = (l_tra == l)
        z1, z2 = mu[mask, 0], mu[mask, 1]
        plt.scatter(z1, z2, color = cmap(l), alpha=0.25, label = l, edgecolors='black')
    #   plt.scatter(mu[:, 0], mu[:, 1], c=l_tra, alpha=0.3, label=l_tra)
    plt.xlabel('z - dim 1')
    plt.ylabel('z - dim 2')
    plt.legend()
    #   plt.colorbar()
    plt.grid()
    plt.title(f'latet space visualization: epoch {epoch}')

    x_l, x_u = min(mu[:, 0]), max(mu[:, 0])
    y_l, y_u = min(mu[:, 1]), max(mu[:, 1])

    filename1 = 'latent_%04d.png' % (epoch)
    plt.savefig(filename1)
    plt.show()
    return x_l, x_u, y_l, y_u

def plot_latent(epoch, verbos=False):
    # display a n*n 2D manifold of digits
    x_l, x_u, y_l, y_u = viz_latent_space(epoch, verbos)
    n = 20
    digit_size = 28
    figsize = 8
    figure = np.zeros((digit_size * n, digit_size * n))
    # linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space
    grid_x = np.linspace(x_l, x_u, n)
    grid_y = np.linspace(y_l, y_u, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = decoder.predict(z_sample)
            digit = x_decoded[0].reshape(digit_size, digit_size)
            figure[
                i * digit_size : (i + 1) * digit_size,
                j * digit_size : (j + 1) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // 2
    end_range = n * digit_size + start_range + 1
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.imshow(figure, cmap="Greys_r")
    plt.title(f'image grid - epoch{epoch}')
    filename1 = 'grid_%04d.png' % (epoch)
    plt.savefig(filename1, bbox_inches='tight')
    plt.show()

"""## creat costum call back for visualization"""

class GANMonitor(keras.callbacks.Callback):
    def __init__(self, period=40):
        self.period = period

    def on_epoch_end(self, epoch, logs=None):
       if epoch % self.period == 0:
           plot_latent(epoch+1, True)

call_back = GANMonitor(12)
epochs = 120

history = vae.fit(F, epochs=epochs, batch_size=128, callbacks = [call_back])

"""## loss plots"""

plt.figure(figsize=(16, 8))
plt.plot([100*i for i in history.history['kl_loss']], label='kl_loss x 100')
plt.plot(history.history['reconstruction_loss'], label='reconstruction loss')
plt.plot(history.history['loss'], label='total loss')
plt.grid()
plt.xlabel('epoch')
plt.ylabel('-')
plt.title('loss of VAE')
plt.legend()
plt.show()

plot_latent(epochs, True)

"""## creat gifs"""

import PIL
import imageio
import glob

def display_image(epoch_no):
  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))

anim_file = 'vae_latent.gif'

with imageio.get_writer(anim_file, mode='I') as writer:
  filenames = glob.glob('latent*.png')
  filenames = sorted(filenames)
  last = -1
  for i,filename in enumerate(filenames):
    frame = 2*(i**0.5)
    if round(frame) > round(last):
      last = frame
    else:
      continue
    image = imageio.imread(filename)
    writer.append_data(image)
  image = imageio.imread(filename)
  writer.append_data(image)

import IPython
if IPython.version_info > (6,2,0,''):
  display.Image(filename=anim_file)

try:
  from google.colab import files
except ImportError:
   pass
else:
  files.download(anim_file)

import PIL
import imageio
import glob

def display_image(epoch_no):
  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))

anim_file = 'vae_grid.gif'

with imageio.get_writer(anim_file, mode='I') as writer:
  filenames = glob.glob('grid*.png')
  filenames = sorted(filenames)
  last = -1
  for i,filename in enumerate(filenames):
    frame = 2*(i**0.5)
    if round(frame) > round(last):
      last = frame
    else:
      continue
    image = imageio.imread(filename)
    writer.append_data(image)
  image = imageio.imread(filename)
  writer.append_data(image)

import IPython
if IPython.version_info > (6,2,0,''):
  display.Image(filename=anim_file)

try:
  from google.colab import files
except ImportError:
   pass
else:
  files.download(anim_file)