{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNDL_miniproj3_Q1_bonus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkFTwlur4f5O",
        "colab_type": "text"
      },
      "source": [
        "# NNDL miniproj3 Question1-Bonus: Efficient Net Transfer Learning\n",
        "sajjad pakdaman    [810195517]\n",
        "\n",
        "fatemeh haghighi   [810195385]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUzq-DKx5NpI",
        "colab_type": "text"
      },
      "source": [
        "## setup\n",
        "import necessary libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS7vtNxwSnpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "ad675267-29a0-429a-ef2c-668477e29e48"
      },
      "source": [
        "# install tf_nighty\n",
        "! pip3 install tf-nightly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.6/dist-packages (2.4.0.dev20200719)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.4.0.dev2020071901)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: tb-nightly<2.4.0a0,>=2.3.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.3.0a20200718)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.30.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.12.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (49.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roxqa3PG5GH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape, MaxPool2D, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hXFkNOE5jkY",
        "colab_type": "text"
      },
      "source": [
        "## load MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCwulshE5Gsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(f_tra, l_tra), (f_tes, l_tes) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk3p5Xur7abg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width, img_height = f_tra.shape[1], f_tra.shape[2]\n",
        "batch_size = 128\n",
        "no_epochs = 50\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "latent_dim = 2\n",
        "num_channels = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWE0d_tO6Nnf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "9c0f768b-efa6-43a2-f838-606587fd2810"
      },
      "source": [
        "plt.imshow(f_tra[0])\n",
        "plt.title(l_tra[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiT-bxHy6ph8",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCK01h--6xMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parse numbers as floats\n",
        "f_tra = (f_tra.astype('float32') / 255).reshape(f_tra.shape[0], img_height, img_width, num_channels)\n",
        "f_tes = (f_tes.astype('float32') / 255).reshape(f_tes.shape[0], img_height, img_width, num_channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF-NCbNj_pLu",
        "colab_type": "text"
      },
      "source": [
        "## sampling layer using reparametrization trick"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNq3hdj7_psd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13sB5vKf8QRx",
        "colab_type": "text"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24cQetfo_Res",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "5de5ac90-ff4a-4c5f-c330-3314a72be1dc"
      },
      "source": [
        "i      = Input(shape=(img_height, img_width, num_channels), name='encoder_input') #(28, 28, 1)\n",
        "x      = layers.Conv2DTranspose(3, 5, activation=\"relu\", strides=1)(i) #(32, 32, 3)\n",
        "\n",
        "base   = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
        "base.trainable = True\n",
        "x      = base(x, training=True) #(1, 1, 1280)\n",
        "\n",
        "# base   = tf.keras.applications.EfficientNetB0(include_top=False, input_shape=(32, 32, 3))\n",
        "# x      = base(x) #(1, 1, 1280)\n",
        "\n",
        "\n",
        "\n",
        "x      = Flatten()(x)  #(1280, )\n",
        "x      = Dense(256)(x) #(256, )\n",
        "x      = Dense(128)(x) #(128, )\n",
        "\n",
        "mu     = Dense(latent_dim, name='z_mu')(x) #(2, )\n",
        "sigma  = Dense(latent_dim, name='z_log_sigma')(x) #(2, )\n",
        "z      = Sampling()([mu, sigma])\n",
        "\n",
        "encoder = keras.Model(i, [mu, sigma, z], name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 32, 32, 3)    78          encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "efficientnetb0 (Functional)     (None, 1, 1, 1280)   4049571     conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1280)         0           efficientnetb0[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          327936      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "z_mu (Dense)                    (None, 2)            258         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_log_sigma (Dense)             (None, 2)            258         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sampling (Sampling)             (None, 2)            0           z_mu[0][0]                       \n",
            "                                                                 z_log_sigma[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 4,410,997\n",
            "Trainable params: 4,368,974\n",
            "Non-trainable params: 42,023\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXcYTdHd_W1v",
        "colab_type": "text"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITf0Wuvp_ZSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "e6f0b0b6-2e70-44b7-af3d-b954e45cba0c"
      },
      "source": [
        "latent_i = keras.Input(shape=(latent_dim,))\n",
        "x        = layers.Dense(16*16, activation=\"relu\")(latent_i)\n",
        "x        = layers.Dense(16*16*16, activation=\"relu\")(x)\n",
        "x        = layers.Reshape((16, 16, 16))(x)\n",
        "x        = layers.Conv2DTranspose(8, 5, activation=\"relu\", strides=1)(x)\n",
        "x        = layers.Conv2DTranspose(4, 5, activation=\"relu\", strides=1)(x)\n",
        "o        = layers.Conv2DTranspose(1, 5, activation=\"sigmoid\", strides=1)(x)\n",
        "\n",
        "decoder = keras.Model(latent_i, o, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               768       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 20, 20, 8)         3208      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 24, 24, 4)         804       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         101       \n",
            "=================================================================\n",
            "Total params: 1,057,553\n",
            "Trainable params: 1,057,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OJ175p8JW2U",
        "colab_type": "text"
      },
      "source": [
        "## VAE Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRCa97lxrTzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "def compute_loss_costum(data, reconstruction, z_log_var, z_mean):\n",
        "    reconstruction_loss = tf.reduce_mean(\n",
        "        keras.losses.binary_crossentropy(data, reconstruction)\n",
        "    )\n",
        "    reconstruction_loss *= 28 * 28\n",
        "    kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "    kl_loss = tf.reduce_mean(kl_loss)\n",
        "    kl_loss *= -0.5\n",
        "    # total_loss = reconstruction_loss\n",
        "    total_loss = reconstruction_loss + kl_loss\n",
        "    log = [data, reconstruction, z_log_var, z_mean, reconstruction_loss, kl_loss, total_loss]\n",
        "    print(log)\n",
        "\n",
        "    return reconstruction_loss, kl_loss, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7yUB4fiJZhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        with open('log.txt', 'w') as f:\n",
        "            pass\n",
        "\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = encoder(data)\n",
        "            reconstruction = decoder(z)\n",
        "            reconstruction_loss, kl_loss, total_loss = compute_loss_costum(data, reconstruction, z_log_var, z_mean)\n",
        "            # reconstruction_loss = tf.reduce_mean(\n",
        "            #     keras.losses.binary_crossentropy(data, reconstruction)\n",
        "            # )\n",
        "            # reconstruction_loss *= 28 * 28\n",
        "            # kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "            # kl_loss = tf.reduce_mean(kl_loss)\n",
        "            # kl_loss *= -0.5\n",
        "            # # total_loss = reconstruction_loss\n",
        "            # total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        return {\n",
        "            \"loss\": total_loss,\n",
        "            \"reconstruction_loss\": reconstruction_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp-Oa4IxJZPu",
        "colab_type": "text"
      },
      "source": [
        "## init the vae"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUWQCgKfKqJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.002))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quv5V-GjSWVN",
        "colab_type": "text"
      },
      "source": [
        "## train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXhoVymmSZ2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "F = f_tra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnN7HY9GQKEt",
        "colab_type": "text"
      },
      "source": [
        "## visualization stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvphh0ZDQJpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def viz_latent_space(epoch, verbos=False):\n",
        "    cmap = plt.cm.get_cmap('jet', 10)\n",
        "    mu, _, _ = encoder.predict(f_tes)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for l in np.unique(l_tes):\n",
        "        mask = (l_tra == l)\n",
        "        z1, z2 = mu[mask, 0], mu[mask, 1]\n",
        "        plt.scatter(z1, z2, color = cmap(l), alpha=0.25, label = l, edgecolors='black')\n",
        "    #   plt.scatter(mu[:, 0], mu[:, 1], c=l_tra, alpha=0.3, label=l_tra)\n",
        "    plt.xlabel('z - dim 1')\n",
        "    plt.ylabel('z - dim 2')\n",
        "    plt.legend()\n",
        "    #   plt.colorbar()\n",
        "    plt.grid()\n",
        "    plt.title(f'latet space visualization: epoch {epoch}')\n",
        "\n",
        "    x_l, x_u = min(mu[:, 0]), max(mu[:, 0])\n",
        "    y_l, y_u = min(mu[:, 1]), max(mu[:, 1])\n",
        "\n",
        "    filename1 = 'latent_%04d.png' % (epoch)\n",
        "    plt.savefig(filename1)\n",
        "    plt.show()\n",
        "    return x_l, x_u, y_l, y_u\n",
        "\n",
        "def plot_latent(epoch, verbos=False):\n",
        "    # display a n*n 2D manifold of digits\n",
        "    x_l, x_u, y_l, y_u = viz_latent_space(epoch, verbos)\n",
        "    n = 20\n",
        "    digit_size = 28\n",
        "    figsize = 8\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(x_l, x_u, n)\n",
        "    grid_y = np.linspace(y_l, y_u, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = decoder.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[\n",
        "                i * digit_size : (i + 1) * digit_size,\n",
        "                j * digit_size : (j + 1) * digit_size,\n",
        "            ] = digit\n",
        "\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range + 1\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap=\"Greys_r\")\n",
        "    plt.title(f'image grid - epoch{epoch+11}')\n",
        "    filename1 = 'grid_%04d.png' % (epoch+11)\n",
        "    plt.savefig(filename1, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMAzXIFaJ4do",
        "colab_type": "text"
      },
      "source": [
        "## creat costum call back for visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJaa917EJ8hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, period=40):\n",
        "        self.period = period\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "       if epoch % self.period == 0:\n",
        "           plot_latent(epoch+1, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKM1ssCGJ9BD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "call_back = GANMonitor(1)\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFRB1gNAKp2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "1e53f08d-ae5a-4b05-d61d-4eac3e8de888"
      },
      "source": [
        "history = vae.fit(F, epochs=epochs, batch_size=100, callbacks = [])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "[<tf.Tensor 'IteratorGetNext:0' shape=(100, 28, 28, 1) dtype=float32>, <tf.Tensor 'decoder/conv2d_transpose_3/Sigmoid:0' shape=(100, 28, 28, 1) dtype=float32>, <tf.Tensor 'encoder/z_log_sigma/BiasAdd:0' shape=(100, 2) dtype=float32>, <tf.Tensor 'encoder/z_mu/BiasAdd:0' shape=(100, 2) dtype=float32>, <tf.Tensor 'mul:0' shape=() dtype=float32>, <tf.Tensor 'mul_1:0' shape=() dtype=float32>, <tf.Tensor 'add_1:0' shape=() dtype=float32>]\n",
            "[<tf.Tensor 'IteratorGetNext:0' shape=(100, 28, 28, 1) dtype=float32>, <tf.Tensor 'decoder/conv2d_transpose_3/Sigmoid:0' shape=(100, 28, 28, 1) dtype=float32>, <tf.Tensor 'encoder/z_log_sigma/BiasAdd:0' shape=(100, 2) dtype=float32>, <tf.Tensor 'encoder/z_mu/BiasAdd:0' shape=(100, 2) dtype=float32>, <tf.Tensor 'mul:0' shape=() dtype=float32>, <tf.Tensor 'mul_1:0' shape=() dtype=float32>, <tf.Tensor 'add_1:0' shape=() dtype=float32>]\n",
            "600/600 [==============================] - 47s 79ms/step - loss: nan - reconstruction_loss: 1007642923.2401 - kl_loss: nan\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 48s 79ms/step - loss: nan - reconstruction_loss: 226.6210 - kl_loss: nan\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 48s 79ms/step - loss: nan - reconstruction_loss: 220.0043 - kl_loss: nan\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 48s 79ms/step - loss: nan - reconstruction_loss: 216.7747 - kl_loss: nan\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 48s 79ms/step - loss: nan - reconstruction_loss: 214.6716 - kl_loss: nan\n",
            "Epoch 6/10\n",
            "112/600 [====>.........................] - ETA: 38s - loss: nan - reconstruction_loss: 213.5974 - kl_loss: nan"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbOBJUN8TdwY",
        "colab_type": "text"
      },
      "source": [
        "## loss plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9smDH9VLxat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history['reconstruction_loss'][0].shape\n",
        "tf.reduce_mean(history.history['reconstruction_loss'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL5B67yVTkV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot([i/100 for i in history.history['kl_loss']], label='kl_loss / 100')\n",
        "plt.plot([tf.reduce_mean(i) for i in history.history['reconstruction_loss']], label='reconstruction loss')\n",
        "plt.plot([tf.reduce_mean(i) for i in history.history['loss']], label='total loss')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('-')\n",
        "plt.title('loss of VAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzOhhmDoQeRz",
        "colab_type": "text"
      },
      "source": [
        "## create gif "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE5R8LhEVb-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL\n",
        "import imageio\n",
        "import glob\n",
        "\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
        "\n",
        "anim_file = 'vae_latent_eff.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('latent*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uauHdxxsViHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS_1uH-aVtQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL\n",
        "import imageio\n",
        "import glob\n",
        "\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
        "\n",
        "anim_file = 'vae_grid_eff.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('grid*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrWvT7F8WFxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wlcufXIjBgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}